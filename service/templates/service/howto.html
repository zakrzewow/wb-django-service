{% extends "service/base.html" %}

{% block content %}
    {% load static %}
    <h2 class="h2 text-secondary">Opis przygotowanej metody</h2>

    Kod potrzebny do przygotowania danych, wytrenowania klasyfikatora, a następnie przedstawienia wyników
    został napisany w języku Python.
    <section>
        <h3 class="h3 text-secondary">Przygotowanie danych</h3>
        <p>
            Dane, których użyliśmy to:
        <ul>
            <li> plik ze współrzędnymi enhancerów dla linii komórkowej GM12878 w formacie BED (zbiór "pozytwyny")
                pobrany z bazy danych <a href="http://www.enhanceratlas.org/">
                    EnhancerAtlas 2.0</a></li>
            <li>zbiór "negatywny" zawierający losowe sekwencje o długościach zbliżonych do enhacerów
                ze zbioru "pozytywnego"
            </li>
            <li><a href="https://www.gencodegenes.org/human/release_43lift37.html">
                plik sekwencji genomowej w formacie FASTA</a></li>
        </ul>

        Najpierw zbiór "pozytywny" został połączony z "negatywnym" dodając etykietę <i>IsEnhancer</i>.
        Do zbioru treningowego zostały z niego wybrane chromosomy o numerach: 2-13, 15-20 i 22.
        Potem, używając biblioteki <i>BioPython</i>, wczytaliśmy plik FASTA. Na podstawie danych z plików BED
        wybraliśmy odpowiednie fragmenty DNA (chromosom, pozycja początkowa i końcowa).
        Następnym krokiem było usunięcie rekordów zawierających literę 'N' (oznaczającą
        że nukleotyd tam jest nieznany (z powodu niedoskonałości eksperymentu sekwencjonowania)
        w sekwencji DNA. Następnie, zliczyliśmy częstości k-merów w sekwencji DNA, pamiętając o odwrotnej
        komplementarności,
        dla <code>k = [2,3,4,5]</code>, dzięki czemu otrzymaliśmy cztery ramki danych o odpowiednio 10, 32, 136 i 512
        kolumnach.
        </p>
    </section>

    <section>
        <h3 class="h3 text-secondary">Wybór klasyfikatora</h3>
        <p class="text-justify">Ponieważ teraz mieliśmy ramki danych zawierające jedynie wartości numeryczne , można
            było przejść do
            trenowania klasyfikatora. Wybraliśmy <code>RandomForestClassifier</code>, model oparty na drzewach.
            Zbiór danych został podzielony na treningowy i walidacyjny, stosując proporcje 70 do 30.
            Zbiór treningowy zawierał 29059 enhancerów i 50672 nie-enhacerów, natomiast walidacyjny
            12454 enhancerów i 21717 nie-enhancerów. Następnie, na zbiorze treningowym, zastosowaliśmy metodę
            <code>RandomSearch</code>, aby znaleźć optymalne hiperparametry dla każdego
            k, stosując 3-krotną kroswalidację.
            Użyliśmy krzywej ROC (wykres) oraz wartości AUC na zbiorze walidacyjnym jako metryki,
            aby porównać otrzymane modele. Wyniki przedstawia tabela:

        <table class="table table-bordered table-hover table-condensed">
            <caption>Wyniki na zbiorze walidacyjnym</caption>
            <thead>
            <tr>
                <th title="Field #1">k-mer</th>
                <th title="Field #2">roc auc</th>
                <th title="Field #3">accuracy</th>
                <th title="Field #4">precison</th>
                <th title="Field #5">recall</th>
                <th title="Field #6">f1</th>

            </tr>
            </thead>
            <tbody>
            <tr>
                <td>4-mer</td>
                <td align="right">0.727</td>
                <td align="right">0.694</td>
                <td align="right">0.686</td>
                <td align="right">0.694</td>
                <td align="right">0.661</td>

            </tr>
            <tr>
                <td>3-mer</td>
                <td align="right">0.721</td>
                <td align="right">0.691</td>
                <td align="right">0.681</td>
                <td align="right">0.691</td>
                <td align="right">0.661</td>

            </tr>
            <tr>
                <td>5-mer</td>
                <td align="right">0.716</td>
                <td align="right">0.682</td>
                <td align="right">0.674</td>
                <td align="right">0.682</td>
                <td align="right">0.64</td>

            </tr>
            <tr>
                <td>2-mer</td>
                <td align="right">0.715</td>
                <td align="right">0.682</td>
                <td align="right">0.668</td>
                <td align="right">0.682</td>
                <td align="right">0.659</td>

            </tr>
            </tbody>
        </table>

         <img src={% static 'service/img/roc.png' %} class="w-100" alt="Image" >

        Model wytrenowany na 4-merach osiągnął najlepsze wyniki
            (AUC = 0.727),
            dlatego został wybrany do dalszych eksperymentów.
        </p>
    </section>

    <section>
        <h3 class="h3 text-secondary">Przygotowanie do wizualizacji</h3>
        <p>Następnie, obliczyliśmy średnią długość enhancera
            dla wszystkich chromosomów - 1744 nukletydów. Na tej podstawie, rozmiar okna na jakie
            została podzielona sekwencja każdego z chromosomów
            ustaliliśmy na 1700. Dla każdego okna, za pomocą wytrenowanego wcześniej modelu,
            obliczyliśmy prawdopodobieństwo 'bycia enhancerem'.Jeśli w danym oknie nukleotydów
            nieznanych było więcej niż 5%,
            zwracane prawdopodobieństwo było średnią predykcją dla danego chromosomu.
        </p>
    </section>

    <section>
        <h3 class="h3 text-secondary">Strona</h3>
        <p>Nasz Web Service umożliwia wybór chromosomu z prawej strony.
            Po kliknięciu wybranego wyświtli się wykres słupkowy, w którym na osi X jest
            numer okna, a na osi Y prawdopodobieństwo, że w danym oknie znajduje się enhancer.
            W lewym dolnym rogu znajduje się przycisk "Pobierz dane",
            który umożliwia pobranie dla wybranego chromosomu danych w formacie .csv,
            gdzie znajdują się dokładne wartości prawdopodobieństw dla każdego okna.
        </p>
    </section>
{% endblock %}
